<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Simple loop tiling for matrix-matrix multiplication #  Having looked at the effect of loop tiling schemes for increasing the throughput of matrix transpose operations in exercise 7, we&rsquo;re now going to look at throughput of the loop-tiling scheme presented in lectures for matrix-matrix multiplication. I provide an implementation of matrix-matrix multiplication in code/exercise08/gemm.c that provides three different variants. A naive triple loop, a tiled version of the triple loop, and a tiled version that manually packs local buffers."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="Loop tiling matrix-matrix multiplication"><meta property="og:description" content="Simple loop tiling for matrix-matrix multiplication #  Having looked at the effect of loop tiling schemes for increasing the throughput of matrix transpose operations in exercise 7, we&rsquo;re now going to look at throughput of the loop-tiling scheme presented in lectures for matrix-matrix multiplication. I provide an implementation of matrix-matrix multiplication in code/exercise08/gemm.c that provides three different variants. A naive triple loop, a tiled version of the triple loop, and a tiled version that manually packs local buffers."><meta property="og:type" content="article"><meta property="og:url" content="https://teaching.wence.uk/comp52315/exercises/exercise08/"><meta property="article:modified_time" content="2022-04-07T18:18:31+01:00"><title>Loop tiling matrix-matrix multiplication | COMP52315 – Performance Engineering</title><link rel=icon href=/comp52315/favicon.svg type=image/x-icon><link rel=stylesheet href=/comp52315/book.min.0cb0b7d6a1ed5d0e95321cc15edca4d6e9cc406149d1f4a3f25fd532f6a3bb38.css integrity="sha256-DLC31qHtXQ6VMhzBXtyk1unMQGFJ0fSj8l/VMvajuzg="><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:true},{left:"$",right:"$",display:false},{left:"\\(",right:"\\)",display:false},{left:"\\[",right:"\\]",display:true}]})});</script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><div class=book-brand><img class=book-center src=/comp52315/logo.svg alt=Logo><h2><a href=/comp52315>COMP52315 – Performance Engineering</a></h2></div><ul><li><span>Administrivia</span><ul><li><a href=/comp52315/setup/contact/>Contact details</a></li><li><a href=/comp52315/setup/hamilton/>Hamilton accounts</a></li><li><a href=/comp52315/setup/configuration/>ssh configuration</a></li><li><a href=/comp52315/setup/unix/>Unix resources</a></li></ul></li><li><span>Exercises</span><ul><li><a href=/comp52315/exercises/exercise01/>Sum reductions</a></li><li><a href=/comp52315/exercises/exercise02/>Caches</a></li><li><a href=/comp52315/exercises/exercise03/>Memory bandwidth</a></li><li><a href=/comp52315/exercises/exercise04/>Roofline analysis</a></li><li><a href=/comp52315/exercises/exercise05/>Models and measurements</a></li><li><a href=/comp52315/exercises/exercise06/>Profiling</a></li><li><a href=/comp52315/exercises/exercise07/>Loop tiling matrix transpose</a></li><li><a href=/comp52315/exercises/exercise08/ class=active>Loop tiling matrix-matrix multiplication</a></li><li><a href=/comp52315/exercises/exercise09/>Compiler feedback and the BLIS DGEMM</a></li><li><a href=/comp52315/exercises/exercise10/>Stencil layer conditions</a></li></ul></li><li><span>Notes</span><ul><li><a href=/comp52315/notes/introduction/>Introduction</a></li><li><a href=/comp52315/notes/memory/>The memory hierarchy</a></li><li><a href=/comp52315/notes/roofline/>Performance models: roofline</a></li><li><a href=/comp52315/notes/measurements/>Measurement and profiling</a></li><li><a href=/comp52315/notes/tiling/>Cache blocking/tiling</a></li></ul></li><li><a href=/comp52315/slides/>Slides</a></li><li><a href=/comp52315/coursework/>Coursework: fast finite elements</a><ul></ul></li><li><a href=/comp52315/resources/>Further resources</a></li><li><a href=/comp52315/acknowledgements/>Acknowledgements</a></li><li><span>Past editions</span><ul><li><a href=/comp52315/past-editions/2020-21/>2020/21</a><ul></ul></li></ul></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/comp52315/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Loop tiling matrix-matrix multiplication</strong>
<label for=toc-control><img src=/comp52315/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#simple-loop-tiling-for-matrix-matrix-multiplication>Simple loop tiling for matrix-matrix multiplication</a><ul><li><a href=#compiling-the-code>Compiling the code</a></li><li><a href=#compare-the-variants>Compare the variants</a></li><li><a href=#inspecting-optimisation-reports>Inspecting optimisation reports</a></li><li><a href=#the-effects-of-tiling-on-memopry-movement>The effects of tiling on memopry movement</a></li></ul></li></ul></nav></aside></header><article class=markdown><blockquote class="book-hint warning"><span>This course page was updated until March 2022 when I left Durham University.
The materials herein are therefore not necessarily still in date.</span></blockquote><h1 id=simple-loop-tiling-for-matrix-matrix-multiplication>Simple loop tiling for matrix-matrix multiplication
<a class=anchor href=#simple-loop-tiling-for-matrix-matrix-multiplication>#</a></h1><p>Having looked at the effect of loop tiling schemes for increasing the
throughput of matrix transpose operations in <a href=https://teaching.wence.uk/comp52315/exercises/exercise07/>exercise 7</a>, we&rsquo;re now going to look at throughput of the
loop-tiling scheme presented in lectures for matrix-matrix
multiplication. I provide an implementation of <a href=https://teaching.wence.uk/comp52315/code/exercise08/gemm.c>matrix-matrix
multiplication</a> in
<code>code/exercise08/gemm.c</code> that provides three
different variants. A naive triple loop, a tiled version of the triple
loop, and a tiled version that manually packs local buffers.</p><h2 id=compiling-the-code>Compiling the code
<a class=anchor href=#compiling-the-code>#</a></h2><p>We&rsquo;ll use the intel compiler to build this code. So after logging in
to Hamilton and downloading, load the relevant modules</p><pre><code>module load gcc/8.2.0
module load intel/2019.5
</code></pre><p>The code can be compiled with <code>icc -O3 -xHOST -o gemm gemm.c</code>.</p><h2 id=compare-the-variants>Compare the variants
<a class=anchor href=#compare-the-variants>#</a></h2><p>You can run the different implemented variants with <code>./gemm N VARIANT</code>
where <code>N</code> is the matrix size and <code>VARIANT</code> is one of <code>BASIC</code>, <code>TILED</code>,
or <code>TILEDPACKED</code>.</p><p>For the <code>TILED</code> and <code>TILEDPACKED</code> variants, the matrix size must be a
multiple of the tile size (which is 64 by default).</p><blockquote class=exercise><h3>Exercise</h3><span>Run the code with matrix sizes from 64 up to 2048.</span></blockquote><blockquote class=question><h3>Question</h3><span>Which version performs the best?</span></blockquote><h2 id=inspecting-optimisation-reports>Inspecting optimisation reports
<a class=anchor href=#inspecting-optimisation-reports>#</a></h2><p>You probably noticed that the <code>TILEDPACKED</code> variant
performed very badly. Before measuring anything, we can look at more
detailed output from the compiler to see if we spot anything
suspicious.</p><p>The Intel compiler can provide excellent diagnostics on what it was
doing when compiling code. Run the compile command again, this time
with <code>icc -O3 -xHOST -qopt-report=5 -qopt-report-file=no-simd-reduction.txt -o gemm gemm.c</code>. Look in the
resulting <code>no-simd-reduction.txt</code> file and search for
<code>tiled_packed_gemm</code> (the name of the routine that performs worse than
expected).</p><blockquote class=question><h3>Question</h3><span>Do you see anything in the optimisation report that stands out as
interesting?</span></blockquote><p>In this case, it seems that we need to give the compiler a hint as to
how to proceed. It did not vectorise the inner loop because it
couldn&rsquo;t prove that it was safe to do so. However, we know it is safe,
so I&rsquo;ve added some annotations to the relevant loop. Instead of having</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-c data-lang=c><span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#111>p</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>p</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>TILESIZE</span><span style=color:#111>;</span> <span style=color:#111>p</span><span style=color:#f92672>++</span><span style=color:#111>)</span> <span style=color:#111>{</span>
  <span style=color:#111>c</span><span style=color:#111>[</span><span style=color:#111>j_</span><span style=color:#f92672>*</span><span style=color:#111>ldc</span> <span style=color:#f92672>+</span> <span style=color:#111>i_</span><span style=color:#111>]</span> <span style=color:#f92672>+=</span> <span style=color:#111>apack</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#f92672>*</span><span style=color:#111>TILESIZE</span> <span style=color:#f92672>+</span> <span style=color:#111>p</span><span style=color:#111>]</span> <span style=color:#f92672>*</span> <span style=color:#111>bpack</span><span style=color:#111>[</span><span style=color:#111>j</span><span style=color:#f92672>*</span><span style=color:#111>TILESIZE</span> <span style=color:#f92672>+</span> <span style=color:#111>p</span><span style=color:#111>];</span>
<span style=color:#111>}</span>
</code></pre></div><p>I use <a href=https://www.openmp.org>OpenMP</a> pragma annotations to instruct
the compiler to vectorise the loop</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-c data-lang=c><span style=color:#00a8c8>double</span> <span style=color:#111>c_</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span>
<span style=color:#75715e>#pragma omp simd reduction (+: c_)
</span><span style=color:#75715e></span><span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#111>p</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>p</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>TILESIZE</span><span style=color:#111>;</span> <span style=color:#111>p</span><span style=color:#f92672>++</span><span style=color:#111>)</span> <span style=color:#111>{</span>
  <span style=color:#111>c_</span> <span style=color:#f92672>+=</span> <span style=color:#111>apack</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#f92672>*</span><span style=color:#111>TILESIZE</span> <span style=color:#f92672>+</span> <span style=color:#111>p</span><span style=color:#111>]</span> <span style=color:#f92672>*</span> <span style=color:#111>bpack</span><span style=color:#111>[</span><span style=color:#111>j</span><span style=color:#f92672>*</span><span style=color:#111>TILESIZE</span> <span style=color:#f92672>+</span> <span style=color:#111>p</span><span style=color:#111>];</span>
<span style=color:#111>}</span>
<span style=color:#111>c</span><span style=color:#111>[</span><span style=color:#111>j_</span><span style=color:#f92672>*</span><span style=color:#111>ldc</span> <span style=color:#f92672>+</span> <span style=color:#111>i_</span><span style=color:#111>]</span> <span style=color:#f92672>+=</span> <span style=color:#111>c_</span><span style=color:#111>;</span>
</code></pre></div><blockquote class=exercise><h3>Exercise</h3><span>Try compiling again, this time adding <code>-DSIMD_REDUCTION</code> to the
compile line (and changing the output file for the optimisation report
to <code>simd-reduction.txt</code></span></blockquote><blockquote class=question><h3>Question</h3><span><p>Look at the new optimisation report and see what the compiler reports
this time.</p><p>Did it manage to vectorise the loop?</p></span></blockquote><blockquote class=exercise><h3>Exercise</h3><span>Benchmark this new version of the <code>TILEDPACKED</code> variant using the same
set of matrix sizes as before.</span></blockquote><blockquote class=question><h3>Question</h3><span>Do you observe any change in the performance?</span></blockquote><h2 id=the-effects-of-tiling-on-memopry-movement>The effects of tiling on memopry movement
<a class=anchor href=#the-effects-of-tiling-on-memopry-movement>#</a></h2><p>As usual, this example is also annotated with likwid markers. We&rsquo;ll
use <code>likwid-perfctr</code> to measure the effect of loop tiling on the total
<em>data movement</em> and measured <em>arithmetic intensity</em> for a large
matrix. We&rsquo;ll need to recompile with likwid enabled for this, so
<code>module load likwid/5.0.1</code> and recompile, adding <code>-DLIKWID_PERFMON -llikwid</code> to the compilation flags.</p><blockquote class=exercise><h3>Exercise</h3><span>Measure the memory and floating point performance for the three
different variatnts using \(N = 3072\) using the <code>MEM_DP</code> group.</span></blockquote><blockquote class=question><h3>Question</h3><span><p>What do you observe in terms of arithmetic intensity and the total
volume of data moved from main memory?</p><p>Can you relate this to the simple model we set up in lectures?</p></span></blockquote></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/wenceorg/comp52315/commit/cdfbd8f86c56d4a17e7e322b59a75940cea4fb4e title="Last modified by Lawrence Mitchell | April 7, 2022" target=_blank rel=noopener><img src=/comp52315/svg/calendar.svg class=book-icon alt=Calendar>
<span>April 7, 2022</span></a></div><div><a class="flex align-center" href=https://github.com/wenceorg/comp52315/edit/main/site/content//exercises/exercise08.md target=_blank rel=noopener><img src=/comp52315/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><div class="flex flex-wrap align-right"><p>© 2020&ndash; <a href=mailto:lawrence.mitchell@durham.ac.uk>Lawrence Mitchell</a> and <a href=https://www.dur.ac.uk/>Durham University</a>.</p><p><a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/><img alt="Creative Commons License" style=border-width:0 src=/comp52315/cc-by-sa.svg></a>
This work is licensed under a <a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/>Creative
Commons Attribution-ShareAlike 4.0 International License</a>.</p></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><nav id=TableOfContents><ul><li><a href=#simple-loop-tiling-for-matrix-matrix-multiplication>Simple loop tiling for matrix-matrix multiplication</a><ul><li><a href=#compiling-the-code>Compiling the code</a></li><li><a href=#compare-the-variants>Compare the variants</a></li><li><a href=#inspecting-optimisation-reports>Inspecting optimisation reports</a></li><li><a href=#the-effects-of-tiling-on-memopry-movement>The effects of tiling on memopry movement</a></li></ul></li></ul></nav></aside></main></body></html>