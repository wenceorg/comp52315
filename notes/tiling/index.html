<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Achieving reasonable performance for loopy code #  Many of the algorithms we encounter in scientific computing have quite &ldquo;simple&rdquo; data access patterns. Numerical code often has multiple nested loops with regular array indexing. This is actually a reason the roofline model is so successful: its optimistic assumptions are not too optimistic.
Despite this simplicity, on hardware with memory caches, we still need to do some work to turn this &ldquo;simple&rdquo; code into something that runs with reasonable performance."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="Cache blocking/tiling"><meta property="og:description" content="Achieving reasonable performance for loopy code #  Many of the algorithms we encounter in scientific computing have quite &ldquo;simple&rdquo; data access patterns. Numerical code often has multiple nested loops with regular array indexing. This is actually a reason the roofline model is so successful: its optimistic assumptions are not too optimistic.
Despite this simplicity, on hardware with memory caches, we still need to do some work to turn this &ldquo;simple&rdquo; code into something that runs with reasonable performance."><meta property="og:type" content="article"><meta property="og:url" content="https://teaching.wence.uk/comp52315/notes/tiling/"><meta property="article:modified_time" content="2022-04-07T18:18:31+01:00"><title>Cache blocking/tiling | COMP52315 – Performance Engineering</title><link rel=icon href=/comp52315/favicon.svg type=image/x-icon><link rel=stylesheet href=/comp52315/book.min.0cb0b7d6a1ed5d0e95321cc15edca4d6e9cc406149d1f4a3f25fd532f6a3bb38.css integrity="sha256-DLC31qHtXQ6VMhzBXtyk1unMQGFJ0fSj8l/VMvajuzg="><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:true},{left:"$",right:"$",display:false},{left:"\\(",right:"\\)",display:false},{left:"\\[",right:"\\]",display:true}]})});</script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><div class=book-brand><img class=book-center src=/comp52315/logo.svg alt=Logo><h2><a href=/comp52315>COMP52315 – Performance Engineering</a></h2></div><ul><li><span>Administrivia</span><ul><li><a href=/comp52315/setup/contact/>Contact details</a></li><li><a href=/comp52315/setup/hamilton/>Hamilton accounts</a></li><li><a href=/comp52315/setup/configuration/>ssh configuration</a></li><li><a href=/comp52315/setup/unix/>Unix resources</a></li></ul></li><li><span>Exercises</span><ul><li><a href=/comp52315/exercises/exercise01/>Sum reductions</a></li><li><a href=/comp52315/exercises/exercise02/>Caches</a></li><li><a href=/comp52315/exercises/exercise03/>Memory bandwidth</a></li><li><a href=/comp52315/exercises/exercise04/>Roofline analysis</a></li><li><a href=/comp52315/exercises/exercise05/>Models and measurements</a></li><li><a href=/comp52315/exercises/exercise06/>Profiling</a></li><li><a href=/comp52315/exercises/exercise07/>Loop tiling matrix transpose</a></li><li><a href=/comp52315/exercises/exercise08/>Loop tiling matrix-matrix multiplication</a></li><li><a href=/comp52315/exercises/exercise09/>Compiler feedback and the BLIS DGEMM</a></li><li><a href=/comp52315/exercises/exercise10/>Stencil layer conditions</a></li></ul></li><li><span>Notes</span><ul><li><a href=/comp52315/notes/introduction/>Introduction</a></li><li><a href=/comp52315/notes/memory/>The memory hierarchy</a></li><li><a href=/comp52315/notes/roofline/>Performance models: roofline</a></li><li><a href=/comp52315/notes/measurements/>Measurement and profiling</a></li><li><a href=/comp52315/notes/tiling/ class=active>Cache blocking/tiling</a></li></ul></li><li><a href=/comp52315/slides/>Slides</a></li><li><a href=/comp52315/coursework/>Coursework: fast finite elements</a><ul></ul></li><li><a href=/comp52315/resources/>Further resources</a></li><li><a href=/comp52315/acknowledgements/>Acknowledgements</a></li><li><span>Past editions</span><ul><li><a href=/comp52315/past-editions/2020-21/>2020/21</a><ul></ul></li></ul></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/comp52315/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Cache blocking/tiling</strong>
<label for=toc-control><img src=/comp52315/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#achieving-reasonable-performance-for-loopy-code>Achieving reasonable performance for loopy code</a><ul><li><a href=#what-can-go-wrong>What can go wrong?</a></li><li><a href=#matrix-transposition>Matrix transposition</a><ul><li><a href=#cache-tiling-for-better-performance>Cache tiling for better performance</a></li></ul></li><li><a href=#matrix-matrix-multiplication>Matrix-matrix multiplication</a></li></ul></li></ul></nav></aside></header><article class=markdown><blockquote class="book-hint warning"><span>This course page was updated until March 2022 when I left Durham University.
The materials herein are therefore not necessarily still in date.</span></blockquote><h1 id=achieving-reasonable-performance-for-loopy-code>Achieving reasonable performance for loopy code
<a class=anchor href=#achieving-reasonable-performance-for-loopy-code>#</a></h1><p>Many of the algorithms we encounter in scientific computing have quite
&ldquo;simple&rdquo; data access patterns. Numerical code often has multiple
nested loops with regular array indexing. This is actually a reason
the roofline model is so successful: its optimistic assumptions are
not <em>too</em> optimistic.</p><p>Despite this simplicity, on hardware with memory caches, we still need
to do some work to turn this &ldquo;simple&rdquo; code into something that runs
with reasonable performance.</p><p>What do we mean by &ldquo;reasonable&rdquo;, perhaps 50% of the relevant resource
bottleneck (memory bandwidth or floating point throughput), and
<em>predictable</em> performance without surprises. That is, we would hope to
achieve this 50% of peak throughout independent of the problem sizes.</p><blockquote class="book-hint info"><span>This does not necessarily mean that our algorithm should have linear
runtime scaling with problem size. For example, it is possible to
achieve constant throughput (FLOPs/s) for matrix-matrix multiply. So
the performance is problem size independent, but since matrix-matrix
multiplication is an $\mathcal{O}(N^3)$ algorithm, bigger problems
will take more than linearly longer.</span></blockquote><h2 id=what-can-go-wrong>What can go wrong?
<a class=anchor href=#what-can-go-wrong>#</a></h2><p>We&rsquo;ll look at two exemplar problems that on the face of it are simple,
and we&rsquo;ll observe how their naive implementation <em>does not</em> result in
&ldquo;surprise-free&rdquo; performance.</p><p>Both our our examples come from dense linear algebra.</p><ol><li><p>Dense matrix transpose</p><p>$$
B_{ij} \gets A_{ji} \quad A, B \in \mathbb{R}^{N\times N}
$$</p></li><li><p>Dense matrix-matrix multiply</p><p>$$
C_{ij} \gets C_{ij} + \sum_{k=1}^{N} A_{ik}B_{kj} \quad A, B, C \in
\mathbb{R}^{N\times N}
$$</p></li></ol><p>These are at &ldquo;opposite&rdquo; ends of the roofline plot. Matrix
transposition has arithmetic intensity of zero (it does no floating
point operations), and is therefore definitely limited by streaming
bandwidth. Conversely, matrix-matrix multiplication does
$\mathcal{O}(N^3)$ floating point operations on $\mathcal{O}(N^2)$
data, for a arithmetic intensity of $\mathcal{O}(N)$ in the <a href=https://teaching.wence.uk/comp52315/notes/roofline/#cache-models>perfect
cache
model</a>.</p><blockquote class="book-hint info"><span>This is actually overly optimistic of what we can achieve, but
matrix-matrix multiplication is nonetheless still firmly in the
flop-limited regime.</span></blockquote><h2 id=matrix-transposition>Matrix transposition
<a class=anchor href=#matrix-transposition>#</a></h2><p>The naive implementation of transposition of a matrix looks like this</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-c data-lang=c><span style=color:#00a8c8>void</span> <span style=color:#75af00>transpose</span><span style=color:#111>(</span><span style=color:#00a8c8>const</span> <span style=color:#00a8c8>double</span> <span style=color:#f92672>*</span> <span style=color:#00a8c8>restrict</span> <span style=color:#111>A</span><span style=color:#111>,</span> <span style=color:#00a8c8>double</span> <span style=color:#f92672>*</span> <span style=color:#00a8c8>restrict</span> <span style=color:#111>B</span><span style=color:#111>,</span> <span style=color:#00a8c8>int</span> <span style=color:#111>N</span><span style=color:#111>)</span>
<span style=color:#111>{</span>
  <span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>i</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>i</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>N</span><span style=color:#111>;</span> <span style=color:#111>i</span><span style=color:#f92672>++</span><span style=color:#111>)</span>
    <span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>j</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>j</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>N</span><span style=color:#111>;</span> <span style=color:#111>j</span><span style=color:#f92672>++</span><span style=color:#111>)</span>
      <span style=color:#111>B</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#f92672>*</span><span style=color:#111>N</span> <span style=color:#f92672>+</span> <span style=color:#111>j</span><span style=color:#111>]</span> <span style=color:#f92672>=</span> <span style=color:#111>A</span><span style=color:#111>[</span><span style=color:#111>j</span><span style=color:#f92672>*</span><span style=color:#111>N</span> <span style=color:#f92672>+</span> <span style=color:#111>i</span><span style=color:#111>];</span>
<span style=color:#111>}</span>
</code></pre></div><p>Since all this is doing is copying data, we might hope to see
performance close to the streaming memory bandwidth, independently of
$N$. Let&rsquo;s have a look. On my laptop, the STREAM triad memory
bandwidth is around 18GB/s.</p><p>Using the <code>transpose</code> code from <a href=https://teaching.wence.uk/comp52315/exercises/exercise07/>exercise 7</a>, I can measure the achieved memory bandwidth for a range of
matrix sizes.</p><pre><code>$ for N in 100 200 300 500 700 1000 1500 2000 2500 3000 4000 5000; do
&gt; ./transpose $N $N
&gt; done
</code></pre><p>This prints a bunch of output, which I elide, but we can put it in a
table</p><table><thead><tr><th>$N$</th><th>BW [MB/s]</th></tr></thead><tbody><tr><td>100</td><td>60000</td></tr><tr><td>200</td><td>46700</td></tr><tr><td>300</td><td>46600</td></tr><tr><td>500</td><td>30600</td></tr><tr><td>700</td><td>23600</td></tr><tr><td>1000</td><td>11900</td></tr><tr><td>1500</td><td>11800</td></tr><tr><td>2000</td><td>4800</td></tr><tr><td>2500</td><td>4300</td></tr><tr><td>3000</td><td>3800</td></tr><tr><td>4000</td><td>3300</td></tr><tr><td>5000</td><td>2900</td></tr></tbody></table><p>So we start out in the cache, and observe bandwidth significantly
above the main memory bandwidth. However, as the matrices get larger,
this falls off, and we end up with throughput much below the streaming
bandwidth.</p><p>If we inspect the code, we notice that we have streaming access to <code>B</code>
(good!), but stride-N access to <code>A</code>. This latter access pattern is bad
for performance because we read a full cache line (64 bytes) each time
we load an entry of <code>A</code>, but only use one double precision entry (8
bytes). As a consequence, we need to hold $LN$ bytes of <code>A</code> in the
cache at once, where <code>L</code> is the number of elements that fit in one
cache line (here 8). Once the matrices get too large, this is no
longer possible.</p><p>Suppose that we estimate the time to write, or read, one byte as the
inverse of the streaming bandwidth</p><p>$$
t_\text{write} = t_\text{read} = \frac{1}{18} \text{ s/GB}
$$</p><p>Remembering that when we are streaming from main memory, that we only
use an eighth of the effective bandwidth for the load of <code>A</code>, then a
model for the total time for transposing an $N\times N$ matrix is
$$
T = N^2(8t_\text{read} + t_\text{write}).
$$
In other words, our model says that in the limit of large $N$ we will
only observe $\frac{1}{9}\text{th}$ of the streaming memory bandwidth.</p><p>Here&rsquo;s a picture of what is going on. The data are laid out typewriter
style, and the red boxes indicate loads that provoke the load of a
full cache line. We see that when writing to <code>B</code>, we always use all of
the loaded cache line, but the same is not true for <code>A</code>.</p><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><figure style=width:100%><img class=scaled src=https://teaching.wence.uk/comp52315/images/manual/strideoneaccess.svg alt="Access to B is stride-1, so works well."><figcaption><p>Access to <code>B</code> is stride-1, so works well.</p></figcaption></figure></div><div class="flex-even markdown-inner"><figure style=width:100%><img class=scaled src=https://teaching.wence.uk/comp52315/images/manual/stridenaccess.svg alt="Access to A is stride-N, and so for large matrices we do not get reuse."><figcaption><p>Access to <code>A</code> is stride-N, and so for large matrices we do not get reuse.</p></figcaption></figure></div></div><h3 id=cache-tiling-for-better-performance>Cache tiling for better performance
<a class=anchor href=#cache-tiling-for-better-performance>#</a></h3><p>What we need to do is to reorder the loops so that we run over little
blocks, transposing them while keeping them in cache. The techniques
we use are called <em>strip mining</em> and <em>loop reordering</em>. We might also
hear the terms <em>cache blocking</em>, <em>loop tiling</em>, or <em>loop blocking</em>.
The idea is to break loops into blocks of consecutive elements and
then reorder for better spatial locality.</p><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><h4 id=original-loops>Original loops</h4><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-c data-lang=c><span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>i</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>i</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>N</span><span style=color:#111>;</span> <span style=color:#111>i</span><span style=color:#f92672>++</span><span style=color:#111>)</span>
  <span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>j</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>j</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>N</span><span style=color:#111>;</span> <span style=color:#111>j</span><span style=color:#f92672>++</span><span style=color:#111>)</span>
    <span style=color:#111>B</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#f92672>*</span><span style=color:#111>N</span> <span style=color:#f92672>+</span> <span style=color:#111>j</span><span style=color:#111>]</span> <span style=color:#f92672>=</span> <span style=color:#111>A</span><span style=color:#111>[</span><span style=color:#111>j</span><span style=color:#f92672>*</span><span style=color:#111>N</span> <span style=color:#f92672>+</span> <span style=color:#111>i</span><span style=color:#111>];</span>
</code></pre></div></div><div class="flex-even markdown-inner"><h4 id=after-loop-blocking>After loop blocking</h4><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-c data-lang=c><span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>ii</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>ii</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>N</span><span style=color:#111>;</span> <span style=color:#111>ii</span> <span style=color:#f92672>+=</span> <span style=color:#111>stridei</span><span style=color:#111>)</span>
  <span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>jj</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>jj</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>N</span><span style=color:#111>;</span> <span style=color:#111>jj</span> <span style=color:#f92672>+=</span> <span style=color:#111>stridej</span><span style=color:#111>)</span>
    <span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>i</span> <span style=color:#f92672>=</span> <span style=color:#111>ii</span><span style=color:#111>;</span> <span style=color:#111>i</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>min</span><span style=color:#111>(</span><span style=color:#111>N</span><span style=color:#111>,</span> <span style=color:#111>ii</span><span style=color:#f92672>+</span><span style=color:#111>stridei</span><span style=color:#111>);</span> <span style=color:#111>i</span><span style=color:#f92672>++</span><span style=color:#111>)</span>
      <span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>j</span> <span style=color:#f92672>=</span> <span style=color:#111>jj</span><span style=color:#111>;</span> <span style=color:#111>j</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>min</span><span style=color:#111>(</span><span style=color:#111>N</span><span style=color:#111>,</span> <span style=color:#111>jj</span><span style=color:#f92672>+</span><span style=color:#111>stridej</span><span style=color:#111>);</span> <span style=color:#111>j</span><span style=color:#f92672>++</span><span style=color:#111>)</span>
        <span style=color:#111>B</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#f92672>*</span><span style=color:#111>N</span> <span style=color:#f92672>+</span> <span style=color:#111>j</span><span style=color:#111>]</span> <span style=color:#f92672>=</span> <span style=color:#111>A</span><span style=color:#111>[</span><span style=color:#111>j</span><span style=color:#f92672>*</span><span style=color:#111>N</span> <span style=color:#f92672>+</span> <span style=color:#111>i</span><span style=color:#111>];</span>
</code></pre></div><p>The loop over <code>i</code> is split into two, with the outer loop strided by
<code>stridei</code>, the <code>j</code> loop is similarly split (with <code>stridej</code>).</p></div></div><p>This changes the iteration order over the matrices</p><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><h4 id=before-loop-blocking>Before loop blocking</h4><figure style=width:100%><img class=scaled src=https://teaching.wence.uk/comp52315/images/manual/originalrowmajororder.svg alt="Iteration over B is good"><figcaption><p>Iteration over <code>B</code> is good</p></figcaption></figure><figure style=width:100%><img class=scaled src=https://teaching.wence.uk/comp52315/images/manual/originalcolmajororder.svg alt="Iteration over A does not get cache reuse"><figcaption><p>Iteration over <code>A</code> does not get cache reuse</p></figcaption></figure></div><div class="flex-even markdown-inner"><h4 id=after-loop-blocking>After loop blocking</h4><figure style=width:100%><img class=scaled src=https://teaching.wence.uk/comp52315/images/manual/tiledrowmajororder.svg alt="Iteration over B is still good"><figcaption><p>Iteration over <code>B</code> is still good</p></figcaption></figure><figure style=width:100%><img class=scaled src=https://teaching.wence.uk/comp52315/images/manual/tiledcolmajororder.svg alt="Iteration over A now gets cache reuse"><figcaption><p>Iteration over <code>A</code> now gets cache reuse</p></figcaption></figure></div></div><p><a href=https://teaching.wence.uk/comp52315/exercises/exercise07/>Exercise 7</a> also provides a blocked
version. So we can run the same experiment as before, except this time
with loop tiling</p><table><thead><tr><th>$N$</th><th>BW (original)</th><th>BW (tiled)</th><th>BW (OpenBLAS)</th></tr></thead><tbody><tr><td>100</td><td>60000</td><td>56200</td><td>63200</td></tr><tr><td>200</td><td>46700</td><td>45300</td><td>57900</td></tr><tr><td>300</td><td>46600</td><td>47800</td><td>58600</td></tr><tr><td>500</td><td>30600</td><td>41600</td><td>54500</td></tr><tr><td>700</td><td>23600</td><td>19200</td><td>35900</td></tr><tr><td>1000</td><td>11900</td><td>12700</td><td>27000</td></tr><tr><td>1500</td><td>11800</td><td>10600</td><td>24100</td></tr><tr><td>2000</td><td>4800</td><td>10500</td><td>23500</td></tr><tr><td>2500</td><td>4300</td><td>10400</td><td>23700</td></tr><tr><td>3000</td><td>3800</td><td>10800</td><td>26600</td></tr><tr><td>4000</td><td>3300</td><td>11200</td><td>22300</td></tr><tr><td>5000</td><td>2900</td><td>12600</td><td>19000</td></tr></tbody></table><p>So now we get consistent performance outside of the cache, with around
60-70% of streaming bandwidth. I also added the bandwidth obtained
from using an optimised transpose from the
<a href=https://www.openblas.net>OpenBLAS</a> library. We see that this is even
slightly higher than the STREAM triad number. I suspect this is because they
have implemented this copy with a <a href=https://vgatherps.github.io/2018-09-02-nontemporal/>non-temporal (or streaming)
store</a>.</p><h2 id=matrix-matrix-multiplication>Matrix-matrix multiplication
<a class=anchor href=#matrix-matrix-multiplication>#</a></h2><p>Now let&rsquo;s look at the matrix multiplication problem. To analyse this
problem, we will postulate a two-level memory system with a small fast
memory, and a large slow memory. We start out with all the data in
slow memory.</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/wenceorg/comp52315/commit/cdfbd8f86c56d4a17e7e322b59a75940cea4fb4e title="Last modified by Lawrence Mitchell | April 7, 2022" target=_blank rel=noopener><img src=/comp52315/svg/calendar.svg class=book-icon alt=Calendar>
<span>April 7, 2022</span></a></div><div><a class="flex align-center" href=https://github.com/wenceorg/comp52315/edit/main/site/content//notes/tiling.md target=_blank rel=noopener><img src=/comp52315/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><div class="flex flex-wrap align-right"><p>© 2020&ndash; <a href=mailto:lawrence.mitchell@durham.ac.uk>Lawrence Mitchell</a> and <a href=https://www.dur.ac.uk/>Durham University</a>.</p><p><a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/><img alt="Creative Commons License" style=border-width:0 src=/comp52315/cc-by-sa.svg></a>
This work is licensed under a <a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/>Creative
Commons Attribution-ShareAlike 4.0 International License</a>.</p></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><nav id=TableOfContents><ul><li><a href=#achieving-reasonable-performance-for-loopy-code>Achieving reasonable performance for loopy code</a><ul><li><a href=#what-can-go-wrong>What can go wrong?</a></li><li><a href=#matrix-transposition>Matrix transposition</a><ul><li><a href=#cache-tiling-for-better-performance>Cache tiling for better performance</a></li></ul></li><li><a href=#matrix-matrix-multiplication>Matrix-matrix multiplication</a></li></ul></li></ul></nav></aside></main></body></html>